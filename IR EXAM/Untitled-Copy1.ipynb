{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['varanasi is a city of music, culture and religion. it is situated in north of india and is one of the oldest living cities of india.', 'new delhi is the capital of india and is a modern city. it is the seat of indian government. it is about 800 kilometres far from varanasi.', \"i love football. it's a wonderful game. it is played in many countries of the world. i just love football world cup.\", 'hockey is national game of india. it is also played in several countries in the world. it is however loosing its popularity to several other games.']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Reading Files into Corpus\n",
    "dir = 'docs\\\\'\n",
    "filelist = os.listdir(dir)\n",
    "N = len(filelist)\n",
    "corpus = []\n",
    "for fn in filelist:\n",
    "    f = open(dir+fn, 'r')\n",
    "    text = f.read().lower()\n",
    "    corpus.append(text)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['800', '0', '1', '0', '0'],\n",
       "       ['about', '0', '1', '0', '0'],\n",
       "       ['also', '0', '0', '0', '1'],\n",
       "       ['and', '2', '1', '0', '0'],\n",
       "       ['capital', '0', '1', '0', '0'],\n",
       "       ['cities', '1', '0', '0', '0'],\n",
       "       ['city', '1', '1', '0', '0'],\n",
       "       ['countries', '0', '0', '1', '1'],\n",
       "       ['culture', '1', '0', '0', '0'],\n",
       "       ['cup', '0', '0', '1', '0'],\n",
       "       ['delhi', '0', '1', '0', '0'],\n",
       "       ['far', '0', '1', '0', '0'],\n",
       "       ['football', '0', '0', '2', '0'],\n",
       "       ['from', '0', '1', '0', '0'],\n",
       "       ['game', '0', '0', '1', '1'],\n",
       "       ['games', '0', '0', '0', '1'],\n",
       "       ['government', '0', '1', '0', '0'],\n",
       "       ['hockey', '0', '0', '0', '1'],\n",
       "       ['however', '0', '0', '0', '1'],\n",
       "       ['in', '1', '0', '1', '2'],\n",
       "       ['india', '2', '1', '0', '1'],\n",
       "       ['indian', '0', '1', '0', '0'],\n",
       "       ['is', '3', '4', '1', '3'],\n",
       "       ['it', '1', '2', '2', '2'],\n",
       "       ['its', '0', '0', '0', '1'],\n",
       "       ['just', '0', '0', '1', '0'],\n",
       "       ['kilometres', '0', '1', '0', '0'],\n",
       "       ['living', '1', '0', '0', '0'],\n",
       "       ['loosing', '0', '0', '0', '1'],\n",
       "       ['love', '0', '0', '2', '0'],\n",
       "       ['many', '0', '0', '1', '0'],\n",
       "       ['modern', '0', '1', '0', '0'],\n",
       "       ['music', '1', '0', '0', '0'],\n",
       "       ['national', '0', '0', '0', '1'],\n",
       "       ['new', '0', '1', '0', '0'],\n",
       "       ['north', '1', '0', '0', '0'],\n",
       "       ['of', '4', '2', '1', '1'],\n",
       "       ['oldest', '1', '0', '0', '0'],\n",
       "       ['one', '1', '0', '0', '0'],\n",
       "       ['other', '0', '0', '0', '1'],\n",
       "       ['played', '0', '0', '1', '1'],\n",
       "       ['popularity', '0', '0', '0', '1'],\n",
       "       ['religion', '1', '0', '0', '0'],\n",
       "       ['seat', '0', '1', '0', '0'],\n",
       "       ['several', '0', '0', '0', '2'],\n",
       "       ['situated', '1', '0', '0', '0'],\n",
       "       ['the', '1', '2', '1', '1'],\n",
       "       ['to', '0', '0', '0', '1'],\n",
       "       ['varanasi', '1', '1', '0', '0'],\n",
       "       ['wonderful', '0', '0', '1', '0'],\n",
       "       ['world', '0', '0', '2', '1']], dtype='<U21')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer  = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X = X.toarray().T\n",
    "vocab = vectorizer.get_feature_names()\n",
    "tf=np.column_stack((vocab,X))\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.30103   ],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.30103   ],\n",
       "       [0.30103   ],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.30103   ],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.12493874],\n",
       "       [0.12493874],\n",
       "       [0.60205999],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.        ],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.30103   ],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.60205999],\n",
       "       [0.        ],\n",
       "       [0.60205999],\n",
       "       [0.30103   ],\n",
       "       [0.60205999],\n",
       "       [0.30103   ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = np.reshape(np.count_nonzero(X, axis=1), (len(vocab), 1))\n",
    "#print(df)\n",
    "idf = np.log10(N/df)\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b38ce31b34ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0midf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mwm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'idf' is not defined"
     ]
    }
   ],
   "source": [
    "wm = X * idf\n",
    "wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2359914789250404"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1_norms=np.sqrt(np.sum(wm[:,0]**2, axis=0))\n",
    "d2_norms=np.sqrt(np.sum(wm[:,1]**2, axis=0))\n",
    "d3_norms=np.sqrt(np.sum(wm[:,2]**2, axis=0))\n",
    "d4_norms=np.sqrt(np.sum(wm[:,3]**2, axis=0))\n",
    "d3_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39369560896838246\n"
     ]
    }
   ],
   "source": [
    "d1_dot_d2 = np.dot(wm[:,0], wm[:,1])\n",
    "d1_dot_d3 = np.dot(wm[:,0], wm[:,2])\n",
    "d2_dot_d3 = np.dot(wm[:,1], wm[:,2])\n",
    "d2_dot_d4 = np.dot(wm[:,1], wm[:,3])\n",
    "d1_dot_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030866461811231835"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_d1_d2= d1_dot_d2/(d1_norms * d2_norms) \n",
    "cos_sim_d1_d3= d1_dot_d3/(d1_norms * d3_norms) \n",
    "cos_sim_d2_d3= d2_dot_d3/(d2_norms * d3_norms) \n",
    "cos_sim_d2_d4= d2_dot_d4/(d2_norms * d4_norms) \n",
    "cos_sim_d2_d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similary of D1 and D2 : 0.09276650021061321\n",
      "Cosine Similary of D1 and D3 : 0.003542270578882795\n",
      "Cosine Similary of D2 and D3 : 0.0\n",
      "Cosine Similary of D2 and D4 : 0.0030866461811231835\n"
     ]
    }
   ],
   "source": [
    "print('Cosine Similary of D1 and D2 : {}'.format(cos_sim_d1_d2))\n",
    "print('Cosine Similary of D1 and D3 : {}'.format(cos_sim_d1_d3))\n",
    "print('Cosine Similary of D2 and D3 : {}'.format(cos_sim_d2_d3))\n",
    "print('Cosine Similary of D2 and D4 : {}'.format(cos_sim_d2_d4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
